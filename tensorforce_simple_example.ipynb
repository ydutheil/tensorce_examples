{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "\n",
    "from tensorforce.environments import Environment\n",
    "from tensorforce.agents import DQNAgent\n",
    "from tensorforce.execution import Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example runs on python 2.7 and most notably tensorforce 0.3.2-5-g8036406\n",
    "This example is derived hevily from tensorforce/examples/quickstart.py\n",
    "\n",
    "We start by setting up the environement. Again we heavily used the examples from tensorforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleEnv(Environment):\n",
    "\n",
    "\n",
    "    def __init__(self, hshift_range=[-2,2], start_pos_range=[-2,2], step_size=0.1):\n",
    "\n",
    "        self.hshift_range = hshift_range\n",
    "        self.start_pos_range = start_pos_range\n",
    "        self.step_size = step_size\n",
    "\n",
    "        self.pos_init = rand.uniform(*self.start_pos_range)\n",
    "        self.pos = self.pos_init\n",
    "        self.hshift = rand.uniform(*self.hshift_range)\n",
    "        print '**** initialization done'\n",
    "\n",
    "        while -(self.pos-self.hshift)**2 +10 > 8.0 :\n",
    "            self.pos_init = rand.uniform(*self.start_pos_range)\n",
    "            self.pos = self.pos_init\n",
    "\n",
    "        \n",
    "    def get_env(self):\n",
    "        return self.pos, self.hshift\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'my stuff __str__'\n",
    "\n",
    "    def reset(self):\n",
    "        print '***** reset of env called'\n",
    "        self.pos_init = rand.uniform(*self.start_pos_range)\n",
    "        self.pos = self.pos_init\n",
    "\n",
    "\n",
    "\n",
    "        self.hshift = rand.uniform(*self.hshift_range)\n",
    "        self.actions_previous = 0\n",
    "\n",
    "\n",
    "        # Here I make sure the initial position is far from the top\n",
    "        while( -(self.pos-self.hshift)**2 +10 > 8.0 and\n",
    "               np.abs(self.pos-self.hshift)<15) :\n",
    "        \n",
    "            self.pos_init = rand.uniform(*self.start_pos_range)\n",
    "            self.pos = self.pos_init\n",
    "\n",
    "\n",
    "        print '*****  state is reset', self.pos\n",
    "        target = -(self.pos-self.hshift)**2 +10\n",
    "        self.target_prev = target\n",
    "        self.target_init = target\n",
    "        return np.array((self.pos, target))\n",
    "\n",
    "    def execute(self, actions):\n",
    "        # action mooves up or down along x by step_size -> +1 or -1\n",
    "\n",
    "        actions_previous = self.actions_previous\n",
    "        self.actions_previous = actions\n",
    "        self.pos_prev = self.pos\n",
    "        if( actions==1):\n",
    "            self.pos += self.step_size\n",
    "        else:\n",
    "            self.pos -= self.step_size\n",
    "        \n",
    "        \n",
    "        target = -(self.pos-self.hshift)**2 +10\n",
    "        if(target < -200) :\n",
    "            print 'killing, reward too bad'\n",
    "            terminal = True\n",
    "            reward = -1\n",
    "        elif( target > 9.8 ) :\n",
    "            print 'killing, reward good engouht', np.abs(self.pos_init - self.hshift)\n",
    "            terminal = True\n",
    "            reward = 10\n",
    "        elif( target > self.target_init and target > self.target_prev):\n",
    "            terminal = False\n",
    "            reward = 0.01\n",
    "        else :\n",
    "            terminal = False\n",
    "            reward = 0\n",
    "\n",
    "        self.target_prev = target\n",
    "        state = np.array((self.pos, target))\n",
    "        return state, terminal, reward\n",
    "    \n",
    "\n",
    "\n",
    "    @property\n",
    "    def states(self):\n",
    "        print '******* states got picked'\n",
    "        return {'shape': (2,), 'type': 'float'}\n",
    "\n",
    "    @property\n",
    "    def actions(self):\n",
    "        print '******* actions got picked'\n",
    "        return {'type': 'int', 'num_actions': 2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be noted is that the states and actions methods provide to tensorforce the way to interact with the environement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I create my environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** initialization done\n"
     ]
    }
   ],
   "source": [
    "env = MySimpleEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I setup some things but it's basically copy-paste from tensorforce examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* states got picked\n",
      "******* actions got picked\n"
     ]
    }
   ],
   "source": [
    "network_spec = [\n",
    "    dict(type='dense', size=32, activation='tanh'),\n",
    "    dict(type='dense', size=32, activation='tanh')\n",
    "]\n",
    "\n",
    "agent = DQNAgent(\n",
    "    states_spec=env.states,\n",
    "    actions_spec=env.actions,\n",
    "    network_spec=network_spec,\n",
    "    batch_size=8,\n",
    "    first_update=10,\n",
    "    target_sync_frequency=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The a runner is created. It is charged to handle the interactions between the agent and the environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(agent=agent, environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a small function that will be called after every episode to give a summary of what happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_finished(r):\n",
    "    print(\"Finished episode {ep} after {ts} timesteps (reward: {reward})\".format(ep=r.episode, ts=r.episode_timestep,\n",
    "                                                                                 reward=r.episode_rewards[-1]))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** reset of env called\n",
      "*****  state is reset 1.3704711474\n",
      "killing, reward good engouht 1.87183069409\n",
      "Finished episode 1 after 153 timesteps (reward: 10.61)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.73128953122\n",
      "killing, reward good engouht 2.19156855071\n",
      "Finished episode 2 after 70 timesteps (reward: 10.37)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.82686329948\n",
      "Finished episode 3 after 201 timesteps (reward: 1.05)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.587868435835\n",
      "Finished episode 4 after 201 timesteps (reward: 0.3)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.8805629577\n",
      "Finished episode 5 after 201 timesteps (reward: 0.79)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.0193700882911\n",
      "killing, reward good engouht 1.68276951164\n",
      "Finished episode 6 after 25 timesteps (reward: 10.16)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.90930736126\n",
      "Finished episode 7 after 201 timesteps (reward: 0.78)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.24416016324\n",
      "Finished episode 8 after 201 timesteps (reward: 0.21)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.84979916655\n",
      "Finished episode 9 after 201 timesteps (reward: 1.1)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.78012901935\n",
      "killing, reward good engouht 2.17848978859\n",
      "Finished episode 10 after 84 timesteps (reward: 10.5)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.63136782098\n",
      "Finished episode 11 after 201 timesteps (reward: 0.7)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.34726754619\n",
      "Finished episode 12 after 201 timesteps (reward: 0.67)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.50660433773\n",
      "killing, reward good engouht 1.68239987697\n",
      "Finished episode 13 after 73 timesteps (reward: 10.41)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.53426062317\n",
      "Finished episode 14 after 201 timesteps (reward: 0.8)\n",
      "***** reset of env called\n",
      "*****  state is reset -0.104853704974\n",
      "Finished episode 15 after 201 timesteps (reward: 0.29)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.747085595479\n",
      "Finished episode 16 after 201 timesteps (reward: 0.79)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.87433553403\n",
      "Finished episode 17 after 201 timesteps (reward: 1.05)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.788923307051\n",
      "Finished episode 18 after 201 timesteps (reward: 0.53)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.90005872222\n",
      "Finished episode 19 after 201 timesteps (reward: 0.68)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.71483520236\n",
      "Finished episode 20 after 201 timesteps (reward: 0.7)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.86483854893\n",
      "Finished episode 21 after 201 timesteps (reward: 0.79)\n",
      "***** reset of env called\n",
      "*****  state is reset -0.725693642143\n",
      "killing, reward good engouht 1.65463415595\n",
      "Finished episode 22 after 191 timesteps (reward: 10.66)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.8390047099\n",
      "Finished episode 23 after 201 timesteps (reward: 0.66)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.97186629283\n",
      "Finished episode 24 after 201 timesteps (reward: 0.14)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.95547908606\n",
      "Finished episode 25 after 201 timesteps (reward: 1.0)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.623186549171\n",
      "Finished episode 26 after 201 timesteps (reward: 0.4)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.40521152452\n",
      "killing, reward good engouht 1.80888783512\n",
      "Finished episode 27 after 156 timesteps (reward: 10.25)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.8712572161\n",
      "Finished episode 28 after 201 timesteps (reward: 1.13)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.83457793332\n",
      "Finished episode 29 after 201 timesteps (reward: 0)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.79791912521\n",
      "killing, reward good engouht 2.38012578505\n",
      "Finished episode 30 after 122 timesteps (reward: 10.7)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.57899926858\n",
      "Finished episode 31 after 201 timesteps (reward: 0.67)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.70634948369\n",
      "Finished episode 32 after 201 timesteps (reward: 1.06)\n",
      "***** reset of env called\n",
      "*****  state is reset -0.75699277678\n",
      "killing, reward good engouht 1.84700538608\n",
      "Finished episode 33 after 114 timesteps (reward: 10.62)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.34822387891\n",
      "Finished episode 34 after 201 timesteps (reward: 0.63)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.506692913033\n",
      "Finished episode 35 after 201 timesteps (reward: 0.5)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.97751981761\n",
      "Finished episode 36 after 201 timesteps (reward: 0.32)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.284617542487\n",
      "Finished episode 37 after 201 timesteps (reward: 0.37)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.99505355453\n",
      "killing, reward good engouht 1.4259075028\n",
      "Finished episode 38 after 60 timesteps (reward: 10.31)\n",
      "***** reset of env called\n",
      "*****  state is reset 0.71402833913\n",
      "Finished episode 39 after 201 timesteps (reward: 0.41)\n",
      "***** reset of env called\n",
      "*****  state is reset -0.701069327243\n",
      "killing, reward good engouht 2.47181185709\n",
      "Finished episode 40 after 95 timesteps (reward: 10.57)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.55989050808\n",
      "killing, reward good engouht 2.36867998036\n",
      "Finished episode 41 after 154 timesteps (reward: 10.6)\n",
      "***** reset of env called\n",
      "*****  state is reset -0.6338340673\n",
      "Finished episode 42 after 201 timesteps (reward: 0.31)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.75257455693\n",
      "Finished episode 43 after 201 timesteps (reward: 1.1)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.1788078765\n",
      "killing, reward good engouht 1.58962602286\n",
      "Finished episode 44 after 56 timesteps (reward: 10.23)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.53681023813\n",
      "Finished episode 45 after 201 timesteps (reward: 0.95)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.8554888981\n",
      "Finished episode 46 after 201 timesteps (reward: 1.05)\n",
      "***** reset of env called\n",
      "*****  state is reset -1.97034929833\n",
      "Finished episode 47 after 201 timesteps (reward: 0.02)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.20281821077\n",
      "killing, reward good engouht 2.42768945881\n",
      "Finished episode 48 after 68 timesteps (reward: 10.43)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.87307888832\n",
      "Finished episode 49 after 201 timesteps (reward: 0.5)\n",
      "***** reset of env called\n",
      "*****  state is reset 1.84840429265\n",
      "Finished episode 50 after 201 timesteps (reward: 0.98)\n"
     ]
    }
   ],
   "source": [
    "runner.run(episodes=50, max_episode_timesteps=200, episode_finished=episode_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f87bd247a90>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(runner.episode_rewards)), runner.episode_rewards, 'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGgCAYAAACXJAxkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAH41JREFUeJzt3X2MHOV9B/Df+Zw7O4nvzEs4++oz\nOCkNDQQn4cVySdNQrCCEECRVRSoquUFqVHoUnERJoOqZw5fkCJUiQoQoTRUgUsAhkQxtJNIiJxjR\n8GIDbkjSONBawSrYTqSwa5xwRndP/zjd2YfP9t15dp/Z3c9HWtk7M955/Mwzz3x35pnZtpRSCgCA\nDOblLgAA0LoEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACAbAQRACAbQQQAyGZ+\n7gK82djYWLz88suxaNGiaGtry10cAGAGUkqxb9++6O3tjXnzZn6eo3RB5OWXX46+vr7cxQAA5mDX\nrl2xbNmyGS9fuiCyaNGiiBj/j3R1dWUuDQAwE9VqNfr6+iaP4zNVuiAycTmmq6tLEAGABjPbYRUG\nqwIA2QgiAEA2gggAkI0gAgBkI4gAANkIIgBANoIIAJCNIAIAZCOIAADZCCIAETE4GDE0NP28oaHx\n+UDxBBGAiGhvj1i//vAwMjQ0Pr29PU+5oNmV7rdmgGINDo4fRAcGDp83NBQxOurbfsTB+lm//uD7\niRCyYcP09Qccv6Y/I+J0K63ON/2ZGxgYDx3r10d0dtYuhOiX4KCmDyI6YVrdoQfXif3AN/0jGxiI\n6OiIOHBg/M9a1I9+aWYEthaRSqZSqaSISJVKpbDP3LAhpYjxP6d7D61got13dGj/R1Ovemr1fumm\nm478f92w4eD86eqk1eqqUcz1+N0SQSQlnTCkdLD9d3TkLkk51TsctHK/NNOQ0eqBrZEIIjOgEz4+\nM/kGQ3m18kFvJnJ9+27lfmmmIUPbbQxzPX43/RiRCUNDB6/5Hjhw5OuOHJnr2o3r0DEhIyOHjxlh\n/O6h6cbMTIyxGR0tfp2t3i/NdHBwPcbtkFGNgtGcGSNSbuqy8bjOXk72pYOOdVaoVc+INNpZaJdm\njkAnXLx6dAqNtgOWmbosH/3SQcfqT1o5sDVaOxFEjmAmnbCOevZqfV270XZAmA19zri5DkxtpX6g\nkYKYIHIcNPbZcXsjcLxm0u8KbOMa5dKUIHKcHPRmxu2N0LqKDAZCxuw0wt1VgkgBHPSOzu2N0Nqc\nPc6jUY5Nbt8tgFvEjs7tjdSTx3uXT7P/XEAZ21xL3Hpfo2A0Z86IMMHlstbm23d5NWtfWbY2V7by\nHItLM8epbAe9Vr9+2mg7ILVRtv2Sg5r1kmmZ2lyjHQcEkeNQxoNeGctUT422A1I7zfrtu5E1+zZp\n9v9frQgix6GsB70yJXPIqVm/fTeiVumXtLnZE0SalGROq7MPlEernKnV5ubGXTNNyp08tLKWuGOg\ngeS4c67etLn6m5+7ABzddLevCiO0guluC534c/36qe+pj6PdvtoM20Kby2PWZ0Qee+yxuOyyy6K3\ntzfa2triwQcfnDI/pRTr16+PpUuXxsKFC2PNmjXxwgsvFFbgViKZ08pa4ds35aLN5THrMyL79++P\nlStXxtVXXx0f+9jHDpt/6623xu233x733ntvrFixIgYGBuLiiy+On/3sZ7FgwYJCCt0KJHNaXbN/\n+6Z8tLk8Zh1ELrnkkrjkkkumnZdSittuuy3+4R/+IS6//PKIiPjmN78ZPT098eCDD8bHP/7xw/7N\nyMhIjIyMTL6vVquzLVJTOloyn5gPAI2u0DEiO3fujN27d8eaNWsmp3V3d8eqVaviiSeemDaIDA8P\nx80331xkMZqCZA5AKyj0rpndu3dHRERPT8+U6T09PZPz3uzGG2+MSqUy+dq1a1eRRQIASiz7XTOd\nnZ3R2dmZuxgAQAaFnhFZsmRJRETs2bNnyvQ9e/ZMzgMAmFBoEFmxYkUsWbIkNm/ePDmtWq3GU089\nFatXry5yVQBAE5j1pZnXXnstXnzxxcn3O3fujO3bt8eJJ54Yy5cvj3Xr1sUXvvCFOP300ydv3+3t\n7Y0rrrii0IIDAI1v1kFk27ZtceGFF06+//SnPx0REWvXro177rknPve5z8X+/fvjk5/8ZLz66qvx\nwQ9+ML7//e97hggAcJi2lFLKXYhDVavV6O7ujkqlEl1dXbmLAwDMwFyP3370DgDIRhABALIRRACA\nbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACA\nbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACA\nbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACA\nbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACA\nbAQRACCbwoPI6OhoDAwMxIoVK2LhwoXxrne9K4aGhiKlVPSqAIAGN7/oD/zyl78cd955Z9x7771x\n5plnxrZt2+ITn/hEdHd3x3XXXVf06gCABlZ4EPnRj34Ul19+eVx66aUREXHaaafF/fffH08//fS0\ny4+MjMTIyMjk+2q1WnSRAICSKvzSzB/90R/F5s2b4xe/+EVERPzXf/1XPP7443HJJZdMu/zw8HB0\nd3dPvvr6+oouEgBQUm2p4MEbY2Nj8fd///dx6623Rnt7e4yOjsYXv/jFuPHGG6ddfrozIn19fVGp\nVKKrq6vIogEANVKtVqO7u3vWx+/CL8088MAD8a1vfSvuu+++OPPMM2P79u2xbt266O3tjbVr1x62\nfGdnZ3R2dhZdDACgARQeRD772c/GDTfcEB//+McjIuK9731v/PKXv4zh4eFpgwgA0LoKHyPy29/+\nNubNm/qx7e3tMTY2VvSqAIAGV/gZkcsuuyy++MUvxvLly+PMM8+M5557Lr7yla/E1VdfXfSqAIAG\nV/hg1X379sXAwEBs2rQp9u7dG729vfEXf/EXsX79+ujo6Djmv5/rYBcAIJ+5Hr8LDyLHSxABgMYz\n1+O335oBALIRRACAbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtB\nBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtB\nBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtB\nBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtB\nBADIRhABALIRRACAbAQRACCbmgSR//u//4u//Mu/jJNOOikWLlwY733ve2Pbtm21WBUA0MDmF/2B\nv/nNb+KCCy6ICy+8MB5++OF4xzveES+88EKccMIJRa8KAGhwhQeRL3/5y9HX1xd333335LQVK1YU\nvRoAoAkUfmnmX//1X+Pcc8+NP//zP49TTjkl3v/+98fXv/71Iy4/MjIS1Wp1ygsAaA2FB5H//d//\njTvvvDNOP/30+Pd///e45ppr4rrrrot777132uWHh4eju7t78tXX11d0kQCAkmpLKaUiP7CjoyPO\nPffc+NGPfjQ57brrroutW7fGE088cdjyIyMjMTIyMvm+Wq1GX19fVCqV6OrqKrJoAECNVKvV6O7u\nnvXxu/AzIkuXLo33vOc9U6b94R/+Ybz00kvTLt/Z2RldXV1TXgBAayg8iFxwwQWxY8eOKdN+8Ytf\nxKmnnlr0qgCABld4EPnUpz4VTz75ZHzpS1+KF198Me67777453/+5+jv7y96VQBAgys8iJx33nmx\nadOmuP/+++Oss86KoaGhuO222+Kqq64qelUAQIMrfLDq8ZrrYBcAIJ/SDFYFAJgpQQQAyEYQAQCy\nEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCy\nEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCy\nEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCy\nEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCy\nEUQAgGxqHkRuueWWaGtri3Xr1tV6VQBAg6lpENm6dWvcddddcfbZZ9dyNQBAg6pZEHnttdfiqquu\niq9//etxwgkn1Go1AEADq1kQ6e/vj0svvTTWrFlz1OVGRkaiWq1OeQEArWF+LT5048aN8eyzz8bW\nrVuPuezw8HDcfPPNtSgGAFByhZ8R2bVrV1x//fXxrW99KxYsWHDM5W+88caoVCqTr127dhVdJACg\npNpSSqnID3zwwQfjox/9aLS3t09OGx0djba2tpg3b16MjIxMmfdm1Wo1uru7o1KpRFdXV5FFAwBq\nZK7H78IvzVx00UXx/PPPT5n2iU98Is4444z4/Oc/f9QQAgC0lsKDyKJFi+Kss86aMu1tb3tbnHTS\nSYdNBwBamyerAgDZ1OSumTd79NFH67EaAKDBOCMCAGQjiAAA2QgiAEA2gggAkI0gAgBkI4gAANkI\nIgBANoIIAJCNIAIAZCOIAADZCCIAQDaCCACQjSACAGQjiAAA2QgiAEA2gggAkI0gAgBkI4gAANkI\nIgBANoIIAJCNIAIAZCOIAADZCCIAQDaCCACQjSACAGQjiAAA2QgiAEA2gggAkI0gAgBkI4gAANkI\nIgBANoIIAJCNIAIAZCOIAADZCCIAQDaCCACQjSACAGQjiAAA2QgiAEA2gggAkI0gAgBkI4gAANkI\nIgBANoIIAJCNIAIAZCOIAADZCCIAQDaCCACQjSACAGQjiAAA2QgiAEA2gggAkE3hQWR4eDjOO++8\nWLRoUZxyyilxxRVXxI4dO4peDQDQBAoPIlu2bIn+/v548skn45FHHok33ngjPvKRj8T+/fuLXhUA\n0ODaUkqpliv41a9+Faecckps2bIlPvShDx1z+Wq1Gt3d3VGpVKKrq6uWRQMACjLX4/f8GpYpIiIq\nlUpERJx44onTzh8ZGYmRkZHJ99VqtdZFAgBKoqaDVcfGxmLdunVxwQUXxFlnnTXtMsPDw9Hd3T35\n6uvrq2WRAIASqemlmWuuuSYefvjhePzxx2PZsmXTLjPdGZG+vj6XZgCggZTu0sy1114b3/ve9+Kx\nxx47YgiJiOjs7IzOzs5aFQMAKLHCg0hKKf7u7/4uNm3aFI8++misWLGi6FUAAE2i8CDS398f9913\nXzz00EOxaNGi2L17d0REdHd3x8KFC4teHQDQwAofI9LW1jbt9Lvvvjv+6q/+6pj/3u27ANB4SjNG\npMaPJQEAmojfmgEAshFEAIBsBBEAIBtBBADIRhABALIRRACAbAQRACAbQQQAyEYQAQCyEUQAgGwE\nEQAgG0EEAMhGEAEAshFEAIBsBBEAIBtBBADIRhABGtbgYMTQ0PTzhobG5wPlJogQETp0GlN7e8T6\n9Ye33aGh8ent7XnKRbno38pNECEidOg0poGBiA0bprbdiTa7YcP4/Hpz0Csf/VvJpZKpVCopIlKl\nUsldlCluuimlDRumn7dhw/j8RrdhQ0oRB/+fb37f6lqhDTSqibba0ZG/zR5pv7E/5VXP/q1V+4q5\nHr8FkRlqlc6lTB162bRKGzheuTrhiTbb0VGbz58Nob6c6tW/tWpfIYjUQat0LmXq0MumVdrA8cjR\nCZcxQJexTNSvfytbX1GPLwiCSJ00e+fS7P+/IqijY6tnJ1y2Dv9QQn25FLHvzuaAXqa+oh5fEASR\nOmrWzqXMHXrZNGsbKFI9OuEynwIv00GI4vq32ba5MvUVte7jBZE6adbOpcwdetk0axuohVp3wmUd\nFCjUl0vR/dtMt28Z+4palkkQqYNm7lzK2qGXTTO3gaKVsROuB6G+fGrRvx2rfZe5r6jVFwRBpMZ0\nLuVUzwClDcxcmTvhWhPqW8eRDuhl7ivKeEZkfv2fXNKYRkenf0DSxPvR0Zl/1uDg+AN0pnvY0tDQ\n+GfN5KFHRX1OI5t4UFHE1Ho49KFWMzGTuoworg0UpYxtYLoHik38Od22ajZHq+9m/n+3mqGhiAMH\nIjo6xv8cGpraF5Str4g4fN+ceH9o2bIoLgsVo6xnRIpUVFouc+qupyK+fTdqXZax3M4I0Owa8Yyf\nu2ZmoRWCSEq1G8Gde4fIdRAq4nRjo9Zl2coNzayM4X8mPEdkFloliKRU3LW6Mg0KnMlOWqsdoogB\nWPWqy5nUwWw6vDK1gWbmbA/awJEJIg2qqNHLjXSvei2+URR5IK5HXc60DmZztuN4yq1znZlG/TYM\n9SCINKBmPCMy0zIVeTmhFp9Vj7qcbUA7WpmOt9wOsDNXz0thAiKNRBBpMM06RuRQx/qGXotxHcea\nPpvPqkddzrQOjlaXrdCWyqZegVVApJEIIg2kqM6lzJ1UEQfYmSjqG2POujyewFZ0uct4dq2sWvXH\n0+BIBJEGUtTBs6ynbYu85FAvubbJ8V7CqkUbKNN4o7Kqd9st074CRyKIUAoz/YberN/yZnOGYq51\nUsu6csA7tlxt90gBsaxfSKifsrQBQYRSKPq21EY0kwPVTOqg3p1Ls4bDIuVqu/W8PEfjKUsbEERo\nGGVJ77V0rDMLZauDsnRkZZdju80l2NpuracMbUAQgZJppLEW9T7Ali2IldVcLvWV4bKa7ZtH7jYw\n1+P3vPr9qg20jul+EKvMBgeP/KNXAwPF/3DexI8VvrleJn6Eq7292PU1qqP9eNqGDVN/PG1g4GB7\n6+iY/Y+YDQ4euZ0ODc2uDdi+eRxvG8imRsFozpwRodGV4RRpI1BPxTrat+EcY7ds3/pr1DMigkiB\nnI4sp3puF2MtZid3x9ksiroDq+jwUI/tq98dV4bgJ4iUgINQOdVzu+gUZ6+RxtKUUdEho+jwUOvt\nq98tTx0IIiVRhlTK4WyXcnJG5PjNJvzOtL6LCg/12r6tvn+X5QuQIFIiZepcy9JAy6BM2wUHj1zq\n8RtQh35Ovbav/Ts/QaRkynK6uSyn7MqiLNul1WmXeRzrYF1UeMi1fe3feQkiJVK2ZO6b57iybZdG\n1Oy/k9TMihrQOhM5H/xm/85HECmJsh70W30nLet2aTTOZDSmmWy3Rg6H9u9yEERKoOyddKuetiz7\ndmk0Ov3G08gh41js3+Ux1+P3/Ho/QK2ZHe0piBPzc5nuSZ8N89S941Tm7dKIJupt/fqIL3xhvD1N\nV7+Ux9Geitro283+3fjaUkopdyEOVa1Wo7u7OyqVSnR1deUuTlOYeKzyxM765vcwF52dB8PtyEju\n0hzd4OD4Y8Wna+9DQ+MHq6IfYw9H04xtcq7H75r91swdd9wRp512WixYsCBWrVoVTz/9dK1WxVFM\nFzomfqdiut+CgJlotN/S8dsnlI02eYhaXCfauHFj6ujoSN/4xjfST3/60/TXf/3XafHixWnPnj3H\n/LeNPEakjJr52jB5NOoYkUYtN82r2dpkqQarnn/++am/v3/y/ejoaOrt7U3Dw8OHLfv666+nSqUy\n+dq1a5cgAiXV6AMDW/3uMcqnmdrkXINI4WNEDhw4EG9961vju9/9blxxxRWT09euXRuvvvpqPPTQ\nQ1OWHxwcjJtvvvmwzzFGBMqnGa5rN9LYFlpDs7TJ0owR+fWvfx2jo6PR09MzZXpPT0/s3r37sOVv\nvPHGqFQqk69du3YVXSSgIIODRx7gPDBQ/hDSaGNbaH7aZA0Hq85UZ2dndHV1TXkBFO3QgdsjIwZs\nk582Oa7w54icfPLJ0d7eHnv27Jkyfc+ePbFkyZKiVwdwTEe6eyxifPqh76EetMmDCg8iHR0dcc45\n58TmzZsnx4iMjY3F5s2b49prry16dQDH5KFXlI02eVBNHmj27W9/O9auXRt33XVXnH/++XHbbbfF\nAw88ED//+c8PGzvyZh5oBgCNZ67H75o84v3KK6+MX/3qV7F+/frYvXt3vO9974vvf//7xwwhAEBr\n8Yh3AOC4leb2XQCAmRJEAIBsBBEAIBtBBADIRhABALIRRACAbAQRACAbQQQAyKYmT1Y9HhPPV6tW\nq5lLAgDM1MRxe7bPSS1dENm3b19ERPT19WUuCQAwW/v27Yvu7u4ZL1+6R7yPjY3Fyy+/HIsWLYq2\ntrZCP7tarUZfX1/s2rXL4+PrQH3Xl/quL/VdX+q7vuZS3yml2LdvX/T29sa8eTMf+VG6MyLz5s2L\nZcuW1XQdXV1dGnIdqe/6Ut/1pb7rS33X12zrezZnQiYYrAoAZCOIAADZtA8ODg7mLkQ9tbe3x4c/\n/OGYP790V6WakvquL/VdX+q7vtR3fdWrvks3WBUAaB0uzQAA2QgiAEA2gggAkI0gAgBkI4gAANm0\nTBC544474rTTTosFCxbEqlWr4umnn85dpKbx2GOPxWWXXRa9vb3R1tYWDz744JT5KaVYv359LF26\nNBYuXBhr1qyJF154IVNpG9vw8HCcd955sWjRojjllFPiiiuuiB07dkxZ5vXXX4/+/v446aST4u1v\nf3v82Z/9WezZsydTiRvbnXfeGWefffbk0yVXr14dDz/88OR8dV1bt9xyS7S1tcW6desmp6nz4gwO\nDkZbW9uU1xlnnDE5v1513RJB5Nvf/nZ8+tOfjptuuimeffbZWLlyZVx88cWxd+/e3EVrCvv374+V\nK1fGHXfcMe38W2+9NW6//fb4p3/6p3jqqafibW97W1x88cXx+uuv17mkjW/Lli3R398fTz75ZDzy\nyCPxxhtvxEc+8pHYv3//5DKf+tSn4t/+7d/iO9/5TmzZsiVefvnl+NjHPpax1I1r2bJlccstt8Qz\nzzwT27Ztiz/90z+Nyy+/PH76059GhLqupa1bt8Zdd90VZ5999pTp6rxYZ555ZrzyyiuTr8cff3xy\nXt3qOrWA888/P/X390++Hx0dTb29vWl4eDhjqZpTRKRNmzZNvh8bG0tLlixJ//iP/zg57dVXX02d\nnZ3p/vvvz1HEprJ3794UEWnLli0ppfG6fctb3pK+853vTC7z3//93yki0hNPPJGrmE3lhBNOSP/y\nL/+irmto37596fTTT0+PPPJI+pM/+ZN0/fXXp5S076LddNNNaeXKldPOq2ddN/0ZkQMHDsQzzzwT\na9asmZw2b968WLNmTTzxxBMZS9Yadu7cGbt3755S/93d3bFq1Sr1X4BKpRIRESeeeGJERDzzzDPx\nxhtvTKnvM844I5YvX66+j9Po6Ghs3Lgx9u/fH6tXr1bXNdTf3x+XXnrplLqN0L5r4YUXXoje3t54\n5zvfGVdddVW89NJLEVHfum765+T++te/jtHR0ejp6ZkyvaenJ37+859nKlXr2L17d0TEtPU/MY+5\nGRsbi3Xr1sUFF1wQZ511VkSM13dHR0csXrx4yrLqe+6ef/75WL16dbz++uvx9re/PTZt2hTvec97\nYvv27eq6BjZu3BjPPvtsbN269bB52nexVq1aFffcc0+8+93vjldeeSVuvvnm+OM//uP4yU9+Ute6\nbvogAs2qv78/fvKTn0y5pkvx3v3ud8f27dujUqnEd7/73Vi7dm1s2bIld7Ga0q5du+L666+PRx55\nJBYsWJC7OE3vkksumfz72WefHatWrYpTTz01HnjggVi4cGHdytH0l2ZOPvnkaG9vP2yk7549e2LJ\nkiWZStU6JupY/Rfr2muvje9973vxwx/+MJYtWzY5fcmSJXHgwIF49dVXpyyvvueuo6Mjfv/3fz/O\nOeecGB4ejpUrV8ZXv/pVdV0DzzzzTOzduzc+8IEPxPz582P+/PmxZcuWuP3222P+/PnR09Ojzmto\n8eLF8Qd/8Afx4osv1rV9N30Q6ejoiHPOOSc2b948OW1sbCw2b94cq1evzliy1rBixYpYsmTJlPqv\nVqvx1FNPqf85SCnFtddeG5s2bYof/OAHsWLFiinzzznnnHjLW94ypb537NgRL730kvouyNjYWIyM\njKjrGrjooovi+eefj+3bt0++zj333Ljqqqsm/67Oa+e1116L//mf/4mlS5fWt30XOvS1pDZu3Jg6\nOzvTPffck372s5+lT37yk2nx4sVp9+7duYvWFPbt25eee+659Nxzz6WISF/5ylfSc889l375y1+m\nlFK65ZZb0uLFi9NDDz2UfvzjH6fLL788rVixIv3ud7/LXPLGc80116Tu7u706KOPpldeeWXy9dvf\n/nZymb/5m79Jy5cvTz/4wQ/Stm3b0urVq9Pq1aszlrpx3XDDDWnLli1p586d6cc//nG64YYbUltb\nW/qP//iPlJK6rodD75pJSZ0X6TOf+Ux69NFH086dO9N//ud/pjVr1qSTTz457d27N6VUv7puiSCS\nUkpf+9rX0vLly1NHR0c6//zz05NPPpm7SE3jhz/8YYqIw15r165NKY3fwjswMJB6enpSZ2dnuuii\ni9KOHTvyFrpBTVfPEZHuvvvuyWV+97vfpb/9279NJ5xwQnrrW9+aPvrRj6ZXXnklX6Eb2NVXX51O\nPfXU1NHRkd7xjnekiy66aDKEpKSu6+HNQUSdF+fKK69MS5cuTR0dHen3fu/30pVXXplefPHFyfn1\nquu2lFIq9hwLAMDMNP0YEQCgvAQRACAbQQQAyEYQAQCyEUQAgGwEEQAgG0EEAMhGEAEAshFEAIBs\nBBEAIBtBBADI5v8B/XmkPjmVogUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87ebc2df10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
